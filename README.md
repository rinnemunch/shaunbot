# ğŸ¤– Shaunbot

A local AI chatbot powered by **LLaMA 3** (via **Ollama**) with a sleek, personalized **PyQt5** interface.  
Built to run **100% offline** with fast, threaded replies, character personas, and a polished UI experience.

---

## ğŸš€ Features

âœ… Chat with LLaMA 3 locally â€” no API key needed  
âœ… Character selector with multiple Shaunbot modes  
âœ… Local knowledge file loading for smarter context  
âœ… Save & load chat history (JSON-based)  
âœ… Typing animation for realistic replies  
âœ… Clean, modern sidebar UI with icons  
âœ… Fully threaded â€” no lag or freezing  
âœ… Graceful error handling for empty bot replies  
âœ… Clear Chat button to reset the convo  
âœ… No internet required after model download  

---

## ğŸ–¼ï¸ Screenshot

![Shaunbot Demo](v2.png)

---

## ğŸ› ï¸ How to Run

1. **Clone the repo:**

```bash
git clone https://github.com/rinnemunch/shaunbot.git
cd shaunbot 
``` 

2. Create and activate a virtual environment: 
```bash 
python -m venv venv
source venv/bin/activate        # On Windows: .\venv\Scripts\activate
``` 

3. Install dependencies: 
```bash 
pip install -r requirements.txt
```

4. Make sure Ollama is installed and running:
```bash 
ollama run llama3
``` 
5. Launch Shaunbot:
```bash 
python main.py
```

## ğŸ“¦ Requirements 
- Python 3.x
- PyQt5
- requests
- Ollama (for running LLaMA 3 locally) 

## ğŸ’¡ Notes 
- All replies are generated locally â€” no internet needed after the model is downloaded
- Uses QThread to keep UI smooth and responsive
- Typing animation is handled by QTimer and can be tweaked in the code
- Knowledge file loads up to 3000 characters to stay prompt-safe 

# ğŸ”“ License 
MIT â€” use it, remix it, break it, improve it.
